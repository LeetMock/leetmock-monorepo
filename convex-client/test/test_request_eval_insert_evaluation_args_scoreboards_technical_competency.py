# coding: utf-8

"""
    Convex App - OpenAPI 3.0

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 0.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from convex_client.models.request_eval_insert_evaluation_args_scoreboards_technical_competency import RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency

class TestRequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency(unittest.TestCase):
    """RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency:
        """Test RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency`
        """
        model = RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency()
        if include_optional:
            return RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency(
                code_quality = convex_client.models.request_eval_insert_evaluation_args_scoreboards_communication_clarification.Request_eval_insertEvaluation_args_scoreboards_communication_clarification(
                    comment = '', 
                    description = '', 
                    examples = [
                        ''
                        ], 
                    max_score = 1.337, 
                    score = 1.337, 
                    test_name = '', ),
                coding_speed = convex_client.models.request_eval_insert_evaluation_args_scoreboards_communication_clarification.Request_eval_insertEvaluation_args_scoreboards_communication_clarification(
                    comment = '', 
                    description = '', 
                    examples = [
                        ''
                        ], 
                    max_score = 1.337, 
                    score = 1.337, 
                    test_name = '', ),
                syntax_error = convex_client.models.request_eval_insert_evaluation_args_scoreboards_communication_clarification.Request_eval_insertEvaluation_args_scoreboards_communication_clarification(
                    comment = '', 
                    description = '', 
                    examples = [
                        ''
                        ], 
                    max_score = 1.337, 
                    score = 1.337, 
                    test_name = '', )
            )
        else:
            return RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency(
                code_quality = convex_client.models.request_eval_insert_evaluation_args_scoreboards_communication_clarification.Request_eval_insertEvaluation_args_scoreboards_communication_clarification(
                    comment = '', 
                    description = '', 
                    examples = [
                        ''
                        ], 
                    max_score = 1.337, 
                    score = 1.337, 
                    test_name = '', ),
                coding_speed = convex_client.models.request_eval_insert_evaluation_args_scoreboards_communication_clarification.Request_eval_insertEvaluation_args_scoreboards_communication_clarification(
                    comment = '', 
                    description = '', 
                    examples = [
                        ''
                        ], 
                    max_score = 1.337, 
                    score = 1.337, 
                    test_name = '', ),
                syntax_error = convex_client.models.request_eval_insert_evaluation_args_scoreboards_communication_clarification.Request_eval_insertEvaluation_args_scoreboards_communication_clarification(
                    comment = '', 
                    description = '', 
                    examples = [
                        ''
                        ], 
                    max_score = 1.337, 
                    score = 1.337, 
                    test_name = '', ),
        )
        """

    def testRequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency(self):
        """Test RequestEvalInsertEvaluationArgsScoreboardsTechnicalCompetency"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
